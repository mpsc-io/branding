"use strict";(self.webpackChunkuser_guide=self.webpackChunkuser_guide||[]).push([[1178],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>p});var a=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=a.createContext({}),c=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},d=function(e){var t=c(e.components);return a.createElement(s.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,i=e.originalType,s=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),u=c(n),p=o,h=u["".concat(s,".").concat(p)]||u[p]||m[p]||i;return n?a.createElement(h,r(r({ref:t},d),{},{components:n})):a.createElement(h,r({ref:t},d))}));function p(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=n.length,r=new Array(i);r[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:o,r[1]=l;for(var c=2;c<i;c++)r[c]=n[c];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},96687:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>r,default:()=>m,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var a=n(87462),o=(n(67294),n(3905));const i={slug:"UseCase-Command-Control",title:"Use-Case Vehicle Fleet Communication using HooT & AI",authors:"amar",tags:["hoot","ucaas","command-control","digital-communications","fleet-management","ai","artificial-intelligence"]},r=void 0,l={permalink:"/blog/UseCase-Command-Control",editUrl:"https://github.com/mpsc-io/branding/edit/main/user_guide/blog/2023-04-16-uc-distributed-command-control.md",source:"@site/blog/2023-04-16-uc-distributed-command-control.md",title:"Use-Case Vehicle Fleet Communication using HooT & AI",description:"The Command and Control (C2) market with respect to fleets of vehicles refers to the technology, software, and services that enable military, government, and commercial organizations to manage and control their fleets of vehicles in real-time.",date:"2023-04-16T00:00:00.000Z",formattedDate:"April 16, 2023",tags:[{label:"hoot",permalink:"/blog/tags/hoot"},{label:"ucaas",permalink:"/blog/tags/ucaas"},{label:"command-control",permalink:"/blog/tags/command-control"},{label:"digital-communications",permalink:"/blog/tags/digital-communications"},{label:"fleet-management",permalink:"/blog/tags/fleet-management"},{label:"ai",permalink:"/blog/tags/ai"},{label:"artificial-intelligence",permalink:"/blog/tags/artificial-intelligence"}],readingTime:5.5,hasTruncateMarker:!1,authors:[{name:"Amar Akshat",title:"Sous-chef",key:"amar"}],frontMatter:{slug:"UseCase-Command-Control",title:"Use-Case Vehicle Fleet Communication using HooT & AI",authors:"amar",tags:["hoot","ucaas","command-control","digital-communications","fleet-management","ai","artificial-intelligence"]},nextItem:{title:"Understanding Kurento Ecosystem & Use Cases",permalink:"/blog/Kurento-DeepDive"}},s={authorsImageUrls:[void 0]},c=[{value:"The HooT Application",id:"the-hoot-application",level:2},{value:"Mission",id:"mission",level:3},{value:"Real-time conference switches and awareness",id:"real-time-conference-switches-and-awareness",level:4},{value:"Mission Updates",id:"mission-updates",level:4},{value:"Client to Vehicle Communication",id:"client-to-vehicle-communication",level:4},{value:"Group Communications and Event Notification",id:"group-communications-and-event-notification",level:4},{value:"Advanced Usage",id:"advanced-usage",level:2}],d={toc:c};function m(e){let{components:t,...i}=e;return(0,o.kt)("wrapper",(0,a.Z)({},d,i,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"The Command and Control (C2) market with respect to fleets of vehicles refers to the technology, software, and services that enable military, government, and commercial organizations to manage and control their fleets of vehicles in real-time."),(0,o.kt)("p",null,"In this market, C2 systems via HooT API are used to coordinate the movement, positioning, and deployment of vehicles, such as military convoys, emergency response vehicles, commercial fleets, and public transportation.\nThese systems use advanced technologies, such as GPS tracking, internet communication, and integration with collaboration engines to provide situational awareness, decision-making support, and efficient resource allocation."),(0,o.kt)("p",null,"HooT's API platform with respect to fleets of vehicles includes a range of solutions, from standalone software applications to integrated hardware and software systems.\nThe API can be customized to meet the specific needs of each organization, depending on the size of the fleet, the type of vehicles, the nature of the mission, and the operational environment."),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(55953).Z,width:"320",height:"320"})),(0,o.kt)("p",null,"The demand for C2 systems in the fleet management market is driven by the increasing need for efficient and secure vehicle operations, improved situational awareness, and real-time decision-making support. This market is expected to continue growing as the demand for advanced fleet management solutions increases, especially in the military and emergency response sectors."),(0,o.kt)("h2",{id:"the-hoot-application"},"The HooT Application"),(0,o.kt)("p",null,"A major fleet management company can automate and relay fleet missions, broadcast alerts, and enable fleet-client communication dynamically with geospatial awareness and realtime information."),(0,o.kt)("h3",{id:"mission"},"Mission"),(0,o.kt)("p",null,"The mission is to send deliveries across a large metropolitan area, while enabling"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"real-time awareness of the current zone"),(0,o.kt)("li",{parentName:"ul"},"update of mission and new workflow adoption"),(0,o.kt)("li",{parentName:"ul"},"client to vehicle communication for any modifications in the plan"),(0,o.kt)("li",{parentName:"ul"},"group communication within fleets"),(0,o.kt)("li",{parentName:"ul"},"point-to-point channel with the vehicle-driver")),(0,o.kt)("p",null,"Delivery of aforementioned workflows can be achieved with an internet-enabled, smart-phone or tablet installed in the vehicle."),(0,o.kt)("h4",{id:"real-time-conference-switches-and-awareness"},"Real-time conference switches and awareness"),(0,o.kt)("p",null,"Using ",(0,o.kt)("inlineCode",{parentName:"p"},"CoreLocation")," in iOS and ",(0,o.kt)("inlineCode",{parentName:"p"},"Geocoder")," in Android, identifying the location of a vehicle and then pinning it to a contextual travel-zone can be accomplished.\nEvery geographically demarcated travel-zone will have an automatically created conference bridge of it's own."),(0,o.kt)("p",null,"Upon entering a new zone, the vehicle could automatically join the conference bridge of that zone for real-time mission updates and regional updates."),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(33933).Z,width:"1205",height:"741"})),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Sample Code for workflow")),(0,o.kt)("p",null,"Getting the location from device"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-kotlin"},"// Android\nimport android.Manifest\nimport android.content.Context\nimport android.content.pm.PackageManager\nimport android.location.Location\nimport androidx.core.app.ActivityCompat\nimport com.google.android.gms.location.FusedLocationProviderClient\nimport com.google.android.gms.location.LocationServices\n\nfun getCurrentLocation(context: Context, callback: (Location?) -> Unit) {\n    val fusedLocationClient: FusedLocationProviderClient = LocationServices.getFusedLocationProviderClient(context)\n    \n    if (ActivityCompat.checkSelfPermission(context, Manifest.permission.ACCESS_FINE_LOCATION) != PackageManager.PERMISSION_GRANTED) {\n        // Permission not granted, handle accordingly\n        callback(null)\n        return\n    }\n    \n    fusedLocationClient.lastLocation.addOnSuccessListener { location: Location? ->\n        // Got last known location. In some rare situations this can be null.\n        callback(location)\n    }\n}\n")),(0,o.kt)("p",null,"Using the location function"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-kotlin"},"getCurrentLocation(this) { location ->\n    // Do something with the location object\n    if (location != null) {\n        val latitude = location.latitude\n        val longitude = location.longitude\n        // ...\n    } else {\n        // Location is null, handle accordingly\n    }\n}\n")),(0,o.kt)("p",null,"API for adding/removing from conference "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},'# Remove the truck_id from previous_zone_conf_id\ncurl -v -H "Authorization: $JWT" \\\n  -X POST --data \'{"remove_users": truck_id,..}\' \\\n  https://devapi.hoot.mx/v1/edit_conference/{previous_zone_conf_id}\n  \n# Add the truck to new_zone_conf_id\ncurl -v -H "Authorization: $JWT" \\\n  -X POST --data \'{"new_participants": truck_id,..}\' \\\n  https://devapi.hoot.mx/v1/edit_conference/{new_zone_conf_id}\n')),(0,o.kt)("h4",{id:"mission-updates"},"Mission Updates"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Live chats can be relayed to all conference users"),(0,o.kt)("li",{parentName:"ul"},"Priority of notifications can be decided by the admin-relayer")),(0,o.kt)("h4",{id:"client-to-vehicle-communication"},"Client to Vehicle Communication"),(0,o.kt)("p",null,"During the course of the mission, upcoming milestones can trigger a communication link to the milestone client."),(0,o.kt)("p",null,"The milestone-client, in case of exceptions and emergencies can join the communication link via web on their mobile devices and communicate about the situation."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Algorithm")),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Identify next N milestones"),(0,o.kt)("li",{parentName:"ol"},"Invite the milestone clients to join a unique link to communicate about their situation if they need to."),(0,o.kt)("li",{parentName:"ol"},"Remove the links once the milestone is complete.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"def milestone_communications(truck, next_communication_size=5):\n    for milestone in truck.milestones[:next_communication_size]:\n        truck.send_comm_link(milestone.client_comm_address)\n")),(0,o.kt)("h4",{id:"group-communications-and-event-notification"},"Group Communications and Event Notification"),(0,o.kt)("p",null,"The truck could automatically subscribe to the event-loop using the ",(0,o.kt)("a",{parentName:"p",href:"/docs/glayr"},"glayr-api"),"."),(0,o.kt)("p",null,"All the urgent-communication events would then flash with the name of the relayer on the dashboard of the driver."),(0,o.kt)("p",null,"Similarly, for the admin to directly communicate with the truck on a private secure channel, they can invoke the API to kickstart the collaboration."),(0,o.kt)("h2",{id:"advanced-usage"},"Advanced Usage"),(0,o.kt)("p",null,"Using AI and collaborating with our team of engineers and data-scientists we can create innovative ways to identify certain situations."),(0,o.kt)("p",null,"One of the use-cases our team came across was to identify distress from conference voice streams."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Goal: Distress Identification from fleet conferences.")," "),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"We created a model trained to detect distress in voice streams."),(0,o.kt)("li",{parentName:"ol"},"We deployed an ",(0,o.kt)("inlineCode",{parentName:"li"},"analyzer")," to our Kurento media stream"),(0,o.kt)("li",{parentName:"ol"},"Identified the distress.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"import tensorflow as tf\nimport numpy as np\nfrom kurento.client import KurentoClient, MediaPipeline, MediaElement, MediaPad, WebRtcEndpoint\n\n# Define the TensorFlow model and input/output tensors\nmodel = tf.keras.models.load_model('distress_model.h5')\ninput_tensor = model.inputs[0]\noutput_tensor = model.outputs[0]\n\n# Connect to Kurento Media Server\nkurento_client = KurentoClient('ws://localhost:8888/kurento')\npipeline = kurento_client.create('MediaPipeline')\nwebrtc = pipeline.create('WebRtcEndpoint')\nwebrtc.connect(pipeline)\n\n# Create a GStreamer element that captures the voice stream and feeds it to the TensorFlow model\ncaps = 'audio/x-raw,format=S16LE,channels=1,layout=interleaved,rate=44100'\nsrc_element = pipeline.create('GstAppSrc', caps=caps)\nsrc_pad = src_element.create_src_pad()\nsrc_element.connect('need-data', on_need_data)\n\n# Define the callback function that processes the voice stream with the TensorFlow model\ndef on_need_data(src, length):\n    # Get the voice stream data from the Kurento WebRtcEndpoint\n    data = webrtc.emit('generate-data-event', length)\n\n    # Preprocess the data for the TensorFlow model\n    audio = np.frombuffer(data, np.int16)\n    audio = tf.audio.encode_wav(audio, sample_rate=44100)\n    audio = tf.io.decode_wav(audio.content)[0]\n    audio = tf.expand_dims(audio, axis=0)\n\n    # Pass the data through the TensorFlow model to make a prediction\n    prediction = model.predict(audio)[0]\n    if prediction[0] > prediction[1]:\n        # No distress detected\n        print('No distress detected')\n    else:\n        # Distress detected\n        print('Distress detected')\n")),(0,o.kt)("p",null,"This code uses TensorFlow to load a pre-trained model that has been trained to detect distress in voice streams.\nIt then creates a Kurento Media Pipeline and a WebRtcEndpoint.\nThe GStreamer element ",(0,o.kt)("inlineCode",{parentName:"p"},"GstAppSrc")," is used to capture the voice stream from the ",(0,o.kt)("inlineCode",{parentName:"p"},"WebRtcEndpoint")," and feed it to the TensorFlow model. The on_need_data callback function is called whenever new data is available, and it processes the data with the TensorFlow model to make a prediction.\nIf the model predicts that distress is present in the voice stream, the callback function outputs a message indicating that distress has been detected."),(0,o.kt)("p",null,"Note that this is a simple example and that the TensorFlow model used in this code is just a placeholder.\nIn practice, you would need to train a more sophisticated model on a large dataset of distressful voice streams in order to achieve accurate results."),(0,o.kt)("p",null,"In a future blog we will discuss training voice-distress models in more detail."))}m.isMDXComponent=!0},55953:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/general-0d8349e344fd41d3aade62a98a0bc35b.png"},33933:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/zonetruck-c35251778e93d2c84cbc2080d17b8feb.png"}}]);